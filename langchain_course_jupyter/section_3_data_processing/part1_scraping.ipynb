{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMi7P/RTuYh7FIC2XKZtZGR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raheelam98/LangChain_Fundamentals/blob/main/langchain_course_jupyter/section_3_data_processing/part1_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Section 3**\n",
        "\n",
        "#### Integrating Linkedin Data Processing\n",
        "\n",
        "**Part 1 - Scraping**\n",
        "\n"
      ],
      "metadata": {
        "id": "hgfd1nzxAYaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required packages:\n",
        "%%capture --no-stderr\n",
        "%pip install -U  langsmith # check\n",
        "%pip install --quiet -U  langchain_google_genai langchain_core langchain langgraph   python-dotenv langsmith"
      ],
      "metadata": {
        "id": "g9UaTqT4BBN1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # packages:\n",
        "# %%capture --no-stderr\n",
        "# %pip install -U langgraph langsmith  langchain   python-dotenv\n",
        ""
      ],
      "metadata": {
        "id": "WZZjpBtCMhYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"ice_breaker\""
      ],
      "metadata": {
        "id": "EQbBLWNmEMrf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# API Keys\n",
        "# Get the GEMINI API key from user data\n",
        "from google.colab import userdata\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "bQjPBVWpETpW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the ChatGoogleGenerativeAI with the Gemini model\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",  # Specify the model to use\n",
        "    max_retries=2,\n",
        "    api_key=gemini_api_key    # Provide the Google API key for authentication\n",
        ")"
      ],
      "metadata": {
        "id": "Ev4V2OtCEYrT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", api_key=gemini_api_key)"
      ],
      "metadata": {
        "id": "CaCCRE2mKCcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "\n",
        "def scrape_linkedin_profile(linkedin_profile_url: str, mock: bool = False):\n",
        "    \"\"\"Scrape information from LinkedIn profiles.\n",
        "    Manually scrape the information from the LinkedIn profile.\"\"\"\n",
        "\n",
        "    if mock:\n",
        "        linkedin_profile_url = \"https://gist.githubusercontent.com/emarco177/0d6a3f93dd06634d95e46a2782ed7490/raw/78233eb934aa9850b689471a604465b188e761a0/eden-marco.json\"\n",
        "        response = requests.get(\n",
        "            linkedin_profile_url,\n",
        "            timeout=10,\n",
        "        )\n",
        "    else:\n",
        "        api_endpoint = \"https://nubela.co/proxycurl/api/v1/linkedin/profile\"\n",
        "        header_dic = {\"Authorization\": f'Bearer {os.environ.get(\"PROXYCURL_API_KEY\")}'}\n",
        "        response = requests.get(\n",
        "            api_endpoint,\n",
        "            params={\"url\": linkedin_profile_url},\n",
        "            headers=header_dic,\n",
        "            timeout=10,\n",
        "        )\n",
        "\n",
        "    # Parse the response\n",
        "    data = response.json()\n",
        "\n",
        "    # Remove extra empty fields  (token:- Validate the payload of the token )\n",
        "    data = {\n",
        "        k: v\n",
        "        for k, v in data.items()\n",
        "        if v not in ([], \"\", None)\n",
        "        and k not in [\"people_also_viewed\", \"certifications\"]\n",
        "    }\n",
        "    if data.get(\"groups\"):\n",
        "        for group_dict in data.get(\"groups\"):\n",
        "            group_dict.pop(\"profile_pic_url\", None)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\n",
        "        scrape_linkedin_profile(\n",
        "            linkedin_profile_url=\"https://www.linkedin.com/in/eden-marco/\",\n",
        "        )\n",
        "    )\n"
      ],
      "metadata": {
        "id": "HIC4yptxQph7",
        "outputId": "f7c9f657-1f2f-4244-b938-2a892674309b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'code': 404, 'description': 'The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.', 'name': 'Not Found'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "\n",
        "print(\"Hello LangChain\")\n",
        "\n",
        "summary_template = \"\"\"\n",
        "    given the information {information} about a person I want you to create:\n",
        "    1. A short summary\n",
        "    2. two interesting facts about them\n",
        "\"\"\"\n",
        "\n",
        "summary_prompt_template = PromptTemplate(\n",
        "        input_variables=[\"information\"], template=summary_template\n",
        "    )\n",
        "\n",
        "chain = summary_prompt_template | llm\n",
        "\n",
        "\n",
        "linkedin_data = scrape_linkedin_profile(linkedin_profile_url=\"https://www.linkedin.com/in/eden-marco/\")\n",
        "\n",
        "res = chain.invoke(input={\"information\": linkedin_data})\n",
        "print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klwraqOCKOu_",
        "outputId": "42dc39f9-6e14-484e-dacd-5ad262a1e016"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello LangChain\n",
            "content=\"It's impossible to create a person's summary and interesting facts based solely on an API error message.  The provided information describes an *error*, not a person.  The error indicates an authentication failure, not characteristics of an individual.  To create a person, I'd need information about their life, personality, etc., not an API response.\\n\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-a55a8066-28d3-427c-975a-f53f886d1468-0' usage_metadata={'input_tokens': 54, 'output_tokens': 74, 'total_tokens': 128, 'input_token_details': {'cache_read': 0}}\n"
          ]
        }
      ]
    }
  ]
}